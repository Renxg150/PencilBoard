{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n",
      "102.8%\n",
      "100.0%\n",
      "112.7%\n",
      "d:\\python\\pyqt_project\\paint_board_final\\paint_board_final_venv\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "#训练集\n",
    "#root是数据存放的位置\n",
    "#train = True表示载入的是训练集的数据\n",
    "#transform=transforms.ToTensor()表示把数据集变成pytorch中基本的数据类型Tensor\n",
    "#download=True表示是否要下载这个数据\n",
    "train_dataset = datasets.MNIST(root='./',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "#train = False表示载入的是测试集的数据\n",
    "test_dataset = datasets.MNIST(root='./',\n",
    "                               train=False,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000]]]),\n 5)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000]]]),\n 5)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "tmp = test_dataset[0][0].tolist()[0]\n",
    "with open(\"./shuju7\",\"w\") as tmp_file:\n",
    "    for i in tmp:\n",
    "        for j in i:\n",
    "            tmp_file.write(\"{:.2f} \".format(j))\n",
    "        tmp_file.write(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#批次大小\n",
    "batch_size = 64\n",
    "\n",
    "#装载训练集\n",
    "#dataset指定了来源\n",
    "#batch_size指定了batch_size的大小\n",
    "#shuffle指定是否打乱\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(train_loader):\n",
    "    inputs,labels = data  # data中包含着inputs和labels data是一个批次的数据和标签\n",
    "    print(inputs.shape)\n",
    "    # [64,1,28,28] 1表示通道数，黑白为1，彩色为3\n",
    "    print(labels.shape)\n",
    "    #[64] 64个标签\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "938"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#定义网络结构\n",
    "#不是le-net5的结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Sequential表示在搭建网络模型中要执行的一系列的步骤\n",
    "        # Dropout中,p=0.5表示50%的神经元不工作\n",
    "        # layer3:输出层 一般输出层中不需要加Dropout\n",
    "        # Conv2d Conv:卷积 2d:表示2维的卷积\n",
    "        # nn.Conv2d的几个参数\n",
    "        # 1：输入通道数：1表示黑白的图片 彩色的话就是3\n",
    "        # 32：输出通道数：表示要生成多少个特征图\n",
    "        # 5:是卷积核的大小，(5,5)表示是5*5的窗口。可以只写一个5\n",
    "        # 1表示步长。步长默认值就是1\n",
    "        # 2表示在padding外面填2圈0 这个相当于samepadding\n",
    "        # nn.MaxPool2d的几个参数\n",
    "        # 第一个2是池化的窗口的大小是2*2 第二个2表示步长为2\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1,32,5,1,2),nn.ReLU(),nn.MaxPool2d(2,2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(32,64,5,1,2),nn.ReLU(),nn.MaxPool2d(2,2))\n",
    "        self.fc1 = nn.Sequential(nn.Linear(64*7*7,1000),nn.Dropout(p=0.5),nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(1000,10),nn.Softmax(dim=1))\n",
    "        # dim=1代表对第一个维度，计算概率值\n",
    "        # 因为batch = 64\n",
    "        # 所以fc1输出的是（64,10）\n",
    "        # 所以dim=1，表示对第二个维度进行softmax求值\n",
    "    def forward(self,x):\n",
    "        # ([64,1,28,28])变成2维的数据->(64,784) 全连接层做计算，必须是2维的数据\n",
    "        # x = x.view(x.size()[0],-1)\n",
    "        # 但是卷积只能对四维的数据进行计算 ([64,1,28,28])\n",
    "        # 64表示批次的数量，1表示通道数 28表示长宽\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        #将原来x四维的数据，改变为2维的数据\n",
    "        # (64,64,7,7)\n",
    "        x = x.view(x.size()[0],-1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "LR = 0.0003\n",
    "# 定义模型\n",
    "model = Net().to(device)\n",
    "\n",
    "#定义代价函数\n",
    "ce_loss = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "#定义优化器 SGD随机梯度下降\n",
    "optimizer = optim.Adam(model.parameters(),LR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train():\n",
    "    # 模型的状态变成训练状态\n",
    "    # 训练状态中，Dropout是起作用的\n",
    "    model.train()\n",
    "    for i,data in enumerate(train_loader):\n",
    "        # 获得一个批次的数据和标签\n",
    "        inputs,labels = data\n",
    "        # 获得模型预测结果(64,10)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = model(inputs)\n",
    "\n",
    "        # 交叉熵代价函数out是(batch,C),labels是(batch)\n",
    "        # batch=64,C表示类别的数量=10\n",
    "        # (batch,c)是(64,10)\n",
    "        # 对于交叉熵代价函数，out和labels不需要shape一致\n",
    "        # 将labels变为独热编码的过程封装在了函数里面\n",
    "        loss = ce_loss(out,labels)\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        #计算梯度\n",
    "        loss.backward()\n",
    "        #修改权值\n",
    "        optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def test():\n",
    "    # 模型的状态变成测试状态\n",
    "    # 测试状态中，模型中的Dropout是不起作用的\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for i,data in enumerate(test_loader):\n",
    "        # 获得一个批次的数据和标签\n",
    "        inputs,labels = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 获得模型预测结果(64,10)\n",
    "        out = model(inputs)\n",
    "        # 得到2个值，获得最大值以及最大值所在的位置\n",
    "        # out表示就是计算out中的最大值，1表示是第一个维度（维度从0开始）\n",
    "        # 没必要关心最大的值是多少，关心最大值所在的位置\n",
    "        _,predicted = torch.max(out,1)\n",
    "        #predicted == labels中会有64个True和false True求和时会是1\n",
    "        #correct是预测正确的数量\n",
    "        correct +=(predicted == labels).sum()\n",
    "    #.item()就是将数值转变为普通的python数值\n",
    "    print(\"Test acc:{0}\".format(correct.item()/len(test_dataset)))\n",
    "\n",
    "    correct = 0\n",
    "    for i,data in enumerate(train_loader):\n",
    "        # 获得一个批次的数据和标签\n",
    "        inputs,labels = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 获得模型预测结果(64,10)\n",
    "        out = model(inputs)\n",
    "        # 得到2个值，获得最大值以及最大值所在的位置\n",
    "        # out表示就是计算out中的最大值，1表示是第一个维度（维度从0开始）\n",
    "        # 没必要关心最大的值是多少，关心最大值所在的位置\n",
    "        _,predicted = torch.max(out,1)\n",
    "        #predicted == labels中会有64个True和false True求和时会是1\n",
    "        #correct是预测正确的数量\n",
    "        correct +=(predicted == labels).sum()\n",
    "    #.item()就是将数值转变为普通的python数值\n",
    "    print(\"Train acc:{0}\".format(correct.item()/len(train_dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Test acc:0.975\n",
      "Train acc:0.9738166666666667\n",
      "epoch: 1\n",
      "Test acc:0.9815\n",
      "Train acc:0.9811166666666666\n",
      "epoch: 2\n",
      "Test acc:0.9852\n",
      "Train acc:0.9852666666666666\n",
      "epoch: 3\n",
      "Test acc:0.9884\n",
      "Train acc:0.9883666666666666\n",
      "epoch: 4\n",
      "Test acc:0.9887\n",
      "Train acc:0.9901666666666666\n",
      "epoch: 5\n",
      "Test acc:0.9906\n",
      "Train acc:0.9924166666666666\n",
      "epoch: 6\n",
      "Test acc:0.9909\n",
      "Train acc:0.9931666666666666\n",
      "epoch: 7\n",
      "Test acc:0.989\n",
      "Train acc:0.9912833333333333\n",
      "epoch: 8\n",
      "Test acc:0.9908\n",
      "Train acc:0.9929833333333333\n",
      "epoch: 9\n",
      "Test acc:0.9918\n",
      "Train acc:0.9937333333333334\n",
      "epoch: 10\n",
      "Test acc:0.9918\n",
      "Train acc:0.9943\n",
      "epoch: 11\n",
      "Test acc:0.9924\n",
      "Train acc:0.9944833333333334\n",
      "epoch: 12\n",
      "Test acc:0.9912\n",
      "Train acc:0.99545\n",
      "epoch: 13\n",
      "Test acc:0.9916\n",
      "Train acc:0.9956\n",
      "epoch: 14\n",
      "Test acc:0.9921\n",
      "Train acc:0.9958166666666667\n",
      "epoch: 15\n",
      "Test acc:0.9917\n",
      "Train acc:0.9957333333333334\n",
      "epoch: 16\n",
      "Test acc:0.9917\n",
      "Train acc:0.9963666666666666\n",
      "epoch: 17\n",
      "Test acc:0.9927\n",
      "Train acc:0.9971666666666666\n",
      "epoch: 18\n",
      "Test acc:0.9913\n",
      "Train acc:0.9959\n",
      "epoch: 19\n",
      "Test acc:0.9926\n",
      "Train acc:0.9970166666666667\n",
      "epoch: 20\n",
      "Test acc:0.9929\n",
      "Train acc:0.99735\n",
      "epoch: 21\n",
      "Test acc:0.9934\n",
      "Train acc:0.9973166666666666\n",
      "epoch: 22\n",
      "Test acc:0.9921\n",
      "Train acc:0.9975333333333334\n",
      "epoch: 23\n",
      "Test acc:0.9927\n",
      "Train acc:0.9976666666666667\n",
      "epoch: 24\n",
      "Test acc:0.992\n",
      "Train acc:0.99705\n",
      "epoch: 25\n",
      "Test acc:0.9919\n",
      "Train acc:0.9977\n",
      "epoch: 26\n",
      "Test acc:0.9934\n",
      "Train acc:0.9981666666666666\n",
      "epoch: 27\n",
      "Test acc:0.9937\n",
      "Train acc:0.9979833333333333\n",
      "epoch: 28\n",
      "Test acc:0.9928\n",
      "Train acc:0.9982666666666666\n",
      "epoch: 29\n",
      "Test acc:0.9931\n",
      "Train acc:0.9981666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ai\\pytorch_project\\project01\\pytorch_venv\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    print('epoch:',epoch)\n",
    "    train()\n",
    "    test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}